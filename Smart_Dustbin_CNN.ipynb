{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxL-mZFCbDd_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization,Dropout, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "path = 'garbage_classification'   # your dataset path\n",
        "labels = ['battery','biological','brown-glass','cardboard','clothes',\n",
        "          'green-glass','metal','paper','plastic','shoes','trash','white-glass']\n",
        "image_size = 128\n",
        "extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\")\n",
        "\n",
        "# =========================\n",
        "# OPTIONAL: balance folders\n",
        "# =========================\n",
        "subfolder_images = {}\n",
        "for root, dirs, files in os.walk(path):\n",
        "    images = [os.path.join(root, f) for f in files if f.lower().endswith(extensions)]\n",
        "    if images:\n",
        "        subfolder_images[root] = images\n",
        "\n",
        "if not subfolder_images:\n",
        "    print(\"No images found. Check your path or extensions.\")\n",
        "else:\n",
        "    min_count = min(len(imgs) for imgs in subfolder_images.values())\n",
        "    print(f\"Minimum images in a folder = {min_count}\")\n",
        "    for folder, images in subfolder_images.items():\n",
        "        if len(images) > min_count:\n",
        "            to_delete = random.sample(images, len(images) - min_count)\n",
        "            print(f\"Deleting {len(to_delete)} images from {folder} ...\")\n",
        "            for img in to_delete:\n",
        "                os.remove(img)\n",
        "\n",
        "# =========================\n",
        "# IMAGE LOADING\n",
        "# =========================\n",
        "def adjust_brightness(img, alpha=1.5, beta=10):\n",
        "    \"\"\"Adjust brightness of image\"\"\"\n",
        "    adjusted_img = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
        "    return adjusted_img\n",
        "\n",
        "def load_images_from_directory(directory, label_list, image_size):\n",
        "    images = []\n",
        "    labels_arr = []\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "    for label in label_list:\n",
        "        folder_path = os.path.join(directory, label)\n",
        "        for file_name in tqdm(os.listdir(folder_path), desc=f\"Loading {label} images\"):\n",
        "            try:\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                img = cv2.imread(file_path)\n",
        "                if img is not None:  # Check if image loaded\n",
        "                    img = cv2.resize(img, (image_size, image_size))\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # grayscale\n",
        "                    img = clahe.apply(img)                      # CLAHE equalization\n",
        "                    img = cv2.bitwise_not(img)                  # invert colors\n",
        "                    img = adjust_brightness(img, alpha=1.5, beta=10)  # brightness\n",
        "\n",
        "                    images.append(img)\n",
        "                    labels_arr.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_name}: {e}\")\n",
        "    return images, labels_arr\n",
        "\n",
        "# Load images\n",
        "x, y = load_images_from_directory(path, labels, image_size)\n",
        "\n",
        "# =========================\n",
        "# TRAIN TEST SPLIT\n",
        "# =========================\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "x_train = np.array(x_train).astype('float32')\n",
        "x_test = np.array(x_test).astype('float32')\n",
        "\n",
        "# Add channel dimension (N,128,128,1)\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Normalize\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot\n",
        "y_train = to_categorical([labels.index(label) for label in y_train], num_classes=len(labels))\n",
        "y_test = to_categorical([labels.index(label) for label in y_test], num_classes=len(labels))\n",
        "\n",
        "print(f\"Train images: {x_train.shape}, Train labels: {y_train.shape}\")\n",
        "print(f\"Test images: {x_test.shape}, Test labels: {y_test.shape}\")\n",
        "\n",
        "# =========================\n",
        "# SHOW SAMPLE IMAGES\n",
        "# =========================\n",
        "colors_dark = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
        "\n",
        "fig, axes = plt.subplots(1, len(labels), figsize=(20, 20))\n",
        "fig.text(s='Sample Image From Each Label', size=18, fontweight='bold',\n",
        "         fontname='monospace', color=colors_dark[1], y=0.85, x=0.4, alpha=0.8)\n",
        "\n",
        "for k, label in enumerate(labels):\n",
        "    try:\n",
        "        idx = np.where(np.argmax(y_train, axis=1) == k)[0][0]\n",
        "        axes[k].imshow(x_train[idx].squeeze(), cmap='gray')\n",
        "        axes[k].set_title(label.replace('_', ' ').title(), fontsize=14)\n",
        "        axes[k].axis('off')\n",
        "    except IndexError:\n",
        "        print(f\"No image found for label: {label}\")\n",
        "        axes[k].axis('off')\n",
        "        axes[k].set_title(f\"{label} (Not Found)\", fontsize=14, color='red')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =========================\n",
        "# MODEL BUILDING\n",
        "# =========================\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(128,128,1)))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(labels), activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# =========================\n",
        "# COMPILE & TRAIN\n",
        "# =========================\n",
        "model.compile(\n",
        "    optimizer='Adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=32,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=30,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        ")\n",
        "\n"
      ]
    }
  ]
}